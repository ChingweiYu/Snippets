\chapter{Problems on sequences}
Arrays are the simplest data structures in computers. Although the structure of an array is very simple, there are still some hard problems. In this chapter, we will go through several hard problems of arrays.

\section{Searching}
%\begin{Exercise}
%Given two arrays $x[1], \dots, x[m]$ and $y[1], \dots, y[n]$, design an algorithm to find two elements $x[i]$ and $y[j]$ such that the absolute value $|x[i] - y[j]|$ is minimized over all possible pairs of $x$ and $y$ elements. A brute force algorithm needs $O(n^2)$ time. Your algorithm should be far more efficient than that. Analyze the time complexity of your algorithm.\school{[NCU CSIE 101]}
%\end{Exercise}
%\begin{Answer}
%First, sort array $x$. Then, for each element $a$ in $y$, use binary search method to find the element $b$ in $x$, such that $|a - b|$ is minimized. In this way, we can find the pair with the minimum absolute value of the difference. Sorting the array takes $O(m \lg m)$ time and binary search takes $O(n \lg m)$ time. The running time is $O((n + m) \lg m)$.
%\end{Answer}

\subsection{$k$-sum problem}

\begin{Exercise}
\Question Given three sets of integers $X$, $Y$, and $Z$, and another integer $k$, we want to know if there exists three numbers $x$, $y$, and $z$, such that $x \in X$, $y \in Y$, and $z \in Z$, and $x + y + z = k$. Design an algorithm to solve this problem. A naive method by checking all possible sums of triples $(x+y+z)$ will take $\Theta(\abs{X}\abs{Y}\abs{Z})$ time. Your algorithm must be more efficient than it. Analyze the time complexity of your algorithm. \label{sequence:3sum} \school{[NCU CSIE 99]}
\Question Given an array of $n$ numbers, and a number $s$, determine whether the array contains $4$ elements whose sum is $s$. Analyze the time efficiency of your algorithm. Your algorithm should be more efficient than $O(n^4)$.  \label{sequence:4sum}  \school{[NCU CSIE 93]}
\end{Exercise}
\begin{Answer}
\paragraph{Problem~\ref{sequence:3sum}} 
This problem is called the \href{https://en.wikipedia.org/wiki/3SUM}{3SUM problem}. Construct a set $Z' = \{k - z \mid z \in Z\}$. The problem is equal to finding $x \in X$, $y \in Y$, and $z \in Z'$, such that $x + y = z$. Sort the sets $Y$ and $Z'$. For each element $x \in X$, construct a set $Y_x = \{y + x \mid y \in Y\}$. If one element $a$ in both  $Y_x$ and $Z'$ exists, then we find an answer. When $Y_x$ is fixed, finding common elements in sorted $Y_x$ and $Z'$ can be done in $O(\abs{Y}+\abs{Z})$ time. Since we apply this operation for each element $x \in X$, the time complexity is $\Theta(\abs{X}\abs{Y}\abs{Z})$.

\begin{remark}
This problem can be solved in $o(n^2)$ time~\cite{Jorgensen2014}.
\end{remark}

\paragraph{Problem~\ref{sequence:4sum}} Let $a$ denote the input array. Let $S_{ij}$ be the sum of $a[i]$ and $[j]$. Sort all $S_{ij}$ in increasing order and store them in an array $A$ of length $L$. The problem is equal to finding two elements in $A$ sum to $s$, which can be solved in time linear in $L$. Since the number of pairs is $O(n^2)$, the sort takes $O(n^2 \lg n)$ time. Moreover, the search takes $O(n^2)$ time. Thus, the time complexity is $O(n^2 \lg n)$.
\end{Answer}

\subsection{Binary search}
\begin{Exercise}
\Question Let $A[n]$ be an array with $n$ elements sorted in ascending order. It is simple to construct an $O(\lg n)$ algorithm to find the position $k$ in $A[n]$ for a given value $v$. Assume that $k$ is much less than $n$ (i.e., $k \ll n$). Write an $O(\lg k)$ time algorithm to search for $k$.
(Note: you do not know the value of $k$ in advance, only $v$ is known) \label{sequence:exponential-search}\school{[YZU CSIE 93]}
\Question Suppose you are given an array of $n$ sorted numbers that has been circularly shifted $m$ positions to the right. For example $\{36, 45, 5, 18, 26, 29\}$ is a sorted array that has been circularly shifted $m = 2$ positions to the right. Give an $O(\lg n)$ algorithm to find the largest number in this array. Note that you don't know what $m$ is. \label{sequence:shift}\school{[CYCU CSIE 89]}
\item Give an efficient algorithm to determine if there exists an integer $i$ such that $A_i = i$ in an array of integers $A_1 < A_2 < \cdots < A_n$. What is the running time of your algorithm? \label{sequence:fixed-point}\school{[NDHU CSIE 96, CYCU CSIE90]}
\end{Exercise}
\begin{Answer}
\paragraph{Problem~\ref{sequence:exponential-search}}
We use linear search to find an index $i$ such that $2^i \leq k < 2^{i+1}$, which takes $O(\lg k)$ time.
Then, we apply binary search for find $x = A[k]$ for $k \in [1 \dots 2^{i + 1}]$, which takes $O(\lg k)$ time as well.

\begin{remark}
This technique is called \href{https://en.wikipedia.org/wiki/Exponential_search}{exponential search}~\cite{Bentley1976}.
\end{remark}

\paragraph{Problem~\ref{sequence:shift}}
Let $m = \frac{n}{2}$. We have three cases:
\begin{enumerate}
\item $A[m] > A[m+1]$: $A[m]$ is the maximum.
\item $A[m] > A[1]$: the maximum locates in $A[m + 1] \sim A[n]$. Recurse.
\item $A[m] < A[1]$: the maximum locates in $A[1] \sim A[m-1]$. Recurse.
\end{enumerate}
Since the problem size is halved in each recursion, the time complexity is $O(\lg n)$.

\paragraph{Problem~\ref{sequence:fixed-point}}
Let $m = \frac{n}{2}$. We have three cases:
\begin{enumerate}
\item $A[m] = m$: $A[m]$ is the fixed point.
\item $A[m] > m$: the fixed point locates in $A[1] \sim A[m - 1]$. Recurse.
\item $A[m] < m$: the fixed point locates in $A[m + 1] \sim A[n]$. Recurse.
\end{enumerate}
Since the problem size is halved in each recursion, the time complexity is $O(\lg n)$.

\end{Answer}

\subsection{Majority problem}
\begin{Exercise}
\Question An array $a[1, \dots, n]$ is said to contain a majority element if there is some element that appears more than $\frac{n}{2}$ times in the array. The task is to determine if $a$ has a majority element and, if so, to find the element. We do not assume that the elements of the array come from some ordered domain such as the integers, so we cannot sort the array or perform comparisons such as $a[i] < a[j]$. However, we assume we are able to test if $a[i] = a[j]$ in constant time. Can you come up with a simple $O(n)$-time algorithm for this problem? \label{sequence:maj1} \school{[CCU CSIE 95]}
\Question Given an $n$-element array $A$ of real numbers, design an $O(n)$ time algorithm which determines whether any value occurs more than $\frac{n}{7}$ times in $A$. \label{sequence:maj2}\school{[NTUT CSIE 102]}
\end{Exercise}

\begin{Answer}
\paragraph{Problem~\ref{sequence:maj1}}
The algorithm is based on the following observation: Let $x$ and $y$ be two distinct elements in $a$. Discarding $x$ and $y$ from $a$ will keep the majority unchanged. 

We choose the first element as a candidate and set $M$ as one. If the next element differs from the candidate, then decrease $M$ by one. If $M$ becomes zero, then choose the next element as a candidate. Repeat this process until all elements are processed. Finally, we need one more pass to test whether the candidate is indeed a majority. Since this is a two pass algorithm, the algorithm runs in linear time.

\begin{remark}
More information can be found in~\cite{Misra1982}.
\end{remark}

\paragraph{Problem~\ref{sequence:maj2}}
If one element occurs more than $\frac{n}{7}$ times in $A$, then the element must be one of $\frac{kn}{7}$-th largest element in $A$, where $1 \leq k \leq 7$. Thus, we can use the selection algorithm to find all $\frac{kn}{7}$-th largest elements in $A$ for all $k$ in linear time. For each of them, determine whether this element occurs more than $\frac{n}{7}$ times in $A$ can also be done in linear time. Thus, the time complexity is linear.

\begin{remark}
For any threshold value $t$, finding element with frequency larger than $\frac{n}{t}$ can be done in linear time (independent from $t$)~\cite{Karp2003}.
\end{remark}
\end{Answer}

\subsection{Saddleback search}

\begin{Exercise}[origin={NTU CSIE 93}]
$M$ is an $n \times n$ integer matrix in which the entries of each row are in increasing order (reading left to right) and the entries in each column are in increasing order (reading top to bottom). Give an efficient algorithm to find the position of an integer $x$ in $M$, or determine that $x$ is not there. Tell how many comparisons of $x$ with matrix entries your algorithm does in the worst case.
\end{Exercise}
\begin{Answer}
For any pair of indices , $i$ and $j$, if $M[i][j] > x$, then we know $M[i][k] \neq x$ for all $j \leq k \leq n$ and $M[k][j] \neq x$ for all $i \leq k \leq n$. Similarly, if $M[i][j] < x$, then we know $M[i][k] \neq x$ for all $1 \leq k \leq j$ and $M[k][j] \neq x$ for all $1 \leq k \leq i$. 

The idea is as follows: in each iteration, we compare an entry with $x$ and the eliminate either a row or a column.

We always compare $x$ of the top-right element of the remaining submatrix. If this entry equals $x$, then we found the answer. If this entry is smaller $x$, then the top row can be discarded. If this entry is larger than $x$, the the rightmost column can be discarded. Since the matrix has $O(n)$ rows and columns, the time complexity is $O(n)$. 

\begin{remark}
This technique is called \emph{saddleback search}~\cite{Bird2006}.
\end{remark}
\end{Answer}


\section{Sorting}

\begin{Exercise}[title={Pancake sorting problem},origin={NCKU CSIE 102},difficulty=1]
Jeremy is a waiter working in a restaurant. The chef there is sloppy; when he prepares a stack of pancakes, they come out all different sizes. When Jeremy delivers the pancakes to the customer, he wants to rearrange them by grabbing several from the top and flipping them over on the way. After repeating this for several times, the smallest pancake is on top, and so on, down to the largest at the bottom. If there are $n$ pancakes, how many flips are required? Design an algorithm to help Jeremy, and analyze its time complexity.
\end{Exercise}
\begin{Answer}
This problem is called the \href{https://en.wikipedia.org/wiki/Pancake_sorting}{pancake sorting problem}. For a stack of pancakes, first locate the largest pancake. Then flip the largest pancake to the top by using one flip and use another flip to move the largest pancake to the bottom. Sort the top $n-1$ pancakes recursively. Since every pancake except the smallest one needs at most two flips to move to the correct position, the number of flips is $2n - 2$.

\begin{remark}
One algorithm with at most $\frac{18}{11}n$ flips exists~\cite{Chitturi2009}.
\end{remark}
\end{Answer}

\begin{Exercise}[origin={NTUT CSIE 95}]
Let $A$ be an array of $n$ arbitrary and distinct numbers. $A$ has the following property: If we imagine $B$ as being sorted version of $A$, then any element that is at position $i$ in array $A$ would, in $B$, be at a position $j$ such that $\abs{i - j} \leq k$. In other words, each element in $A$ is not farther than $k$ positions away from where it belongs in the sorted version of $A$. Suppose you are given such an array $A$, and you are told that $A$ has this property for a particular value $k$ (that value of $k$ is also given to you). Design an $O(n \lg k)$ time algorithm for sorting $A$.
\end{Exercise}
\begin{Answer}
Initially, insert the first $2k$ elements into a min heap; then, repeat the following process $n - 2k$ times. In iteration $i$, delete the minimum value in the heap and output it; then, insert the $(2k + i)$-th element into the heap. After loops terminates, sort the elements in the heap by the heap sort and output it.

For any position $i$ in the sorted array, the possible positions in the unsorted array are from $i - k$ to $i + k$, so using a min heap guarantees the correctness. 
Since the size of heap is $O(k)$, the insertion and deletion takes $O(\lg k)$ time. 
Since we insert and delete $O(n)$ times, the time complexity is $O(n \lg k)$.
\end{Answer}

\begin{Exercise}[origin={NCU CSIE 98}]
The input is a sequence of $n$ integers with many duplications, such that the number of distinct integers in the sequence is $O(\lg n)$.
Design a sorting algorithm to sort such sequences using at most $O(n \lg \lg n)$ comparisons in the worst case.
\end{Exercise}
\begin{Answer}
Augment an AVL-tree by creating a count field in each tree node. First process all elements in the input sequentially. For each integer $x$ in input, search for $x$ in the tree; if $x$ has been inserted, then increment the $x$'s count; otherwise, insert $x$ into the tree and initialize the count to $1$. Then, in-order traverse the data structure and output the elements with its multiplicity. Since the distinct integers is $O(\lg n)$, both of search and insertion take $O(\lg \lg n)$ time. Since the number of insertion and search is $O(n)$, the time complexity $O(n \lg \lg n)$.
\end{Answer}

\subsection{Bucket sort}
\begin{Exercise}[origin={NDHU CSIE 97}]
We are given $n$ points in an unit circle, $ p_i$ = $(x_i, y_i)$, such that $0 < \sqrt{x_i^2 + y_i^2} < 1$, for $i = 1, \dots, n$. Suppose that the points are uniformly distributed; that is, the probability of finding a point in any region of the circle is proportional to the area of that region. Design and prove a $\Theta(n)$ expected-time algorithm to sort the $n$ points by their distance $d_i = \sqrt{x_i^2 + y_i^2}$ from the origin. (Hints: Design the bucket sizes in Bucket-Sort to reflect the uniform distribution of the points in the unit circle.)
\end{Exercise}
\begin{Answer}
Divide the circle into $n$ concentric circles with radii $\sqrt{\frac{1}{n}}, \sqrt{\frac{2}{n}}, \dots, 1$. The area of the $i$th level is $\pi {\sqrt{\frac{i}{n}}}^2 - \pi {\sqrt{\frac{i-1}{n}}}^2 = \pi/n$. Since the areas are equal-size, the probability of point locates in any level is $1/n$. So we can partition the points by their levels and use the bucket sort to sort these points.
\end{Answer}

\section{Order statistics}
\begin{Exercise}[origin={NTUST CSIE 98},difficulty=1]
It is trivial to find the median of the integers in the sorted array $a$ with median $= a[\lfloor \frac{n}{2} \rfloor]$. Suppose we have $3n$ distinct integers that are randomly stored in arrays $a[0 \dots n-1]$, $b[0 \dots n-1]$, and $c[0 \dots n-1]$, and each array is sorted independently. Write an algorithm to find the median of these $3n$ distinct integers. Please note that you are not allowed to merge arrays $a$, $b$, and $c$ into a $3n$ integer array and then perform sorting. 
\end{Exercise}
\begin{Answer}
The idea is as follows:  in each iteration, we eliminate some elements that cannot be the answer. Repeat this process until only one element remains.

Let $N$ be the number of all remaining elements and our goal is to find the $k$-th smallest element. Initially, we have $N = 3n$ and $k = \frac{N}{2}$. In each iteration, we collect the middle elements of all arrays as a set $P$. If $k < \frac{N}{2}$, then we pick the array with the maximum middle element. In this array, the elements that are larger than the middle element must be larger than $\frac{N}{2}$ elements in all elements. Thus, we can remove these elements safely. The case in which $k > \frac{N}{2}$ is symmetric. We adjust the $k$ value and recurse on the remaining elements. Since one array is halved in each iteration, the number of iterations is $O(\lg n)$. Since each iteration takes constant time, the time complexity is $O(\lg n)$.
\end{Answer}

\begin{Exercise}[origin={NCU CSIE 96}]
Suppose that $k$ workers are given the task of scanning through a shelf of books in search of a given piece of information. To get the job done efficiently, the books are to be partitioned among $k$ workers. To avoid the need to rearrange the books, it would be simplest to divide the shelf into $k$ regions and assign each region to one worker. Each book can only be scanned by one worker. you are asked to find the fairest way to divide the shelf up. For example, if a shelf has 9 books of sizes 100, 200, 300, 400, 500, 600, 700, 800 and 900 pages, and $k = 3$, the fairest possible partition for the shelf would be
\[ 100~200~300~400~500 \mid 600~700 \mid 800~900 \]
where the largest job is 1700 pages and the smallest job 1300. In general, we have the following problem: Given an arrangement $S$ of $n$ nonnegative numbers, and an integer $k$, partition $S$ into $k$ regions so as to minimize the difference between the largest and the smallest sum over all regions.
Design algorithm to find an optimal solution for any given $k \leq n$.
\end{Exercise}
\begin{Answer}
For a number $d$, we can verify whether these $n$ books can be partitions into $k$ parts with the maximum load at most $d$ in linear time.
Moreover, the minimum feasible $d$ value must be $\sum_{k=i}^j S_k$ for some $i$ and $j$.
Create a matrix $M$, such that $M[i][j] = \sum_{k=i}^j S_k$; note that all rows and columns in $M$ are in increasing order.
Our goal is to find a pair of indices, $i$ and $j$, such that $M[i][j]$ is the minimum feasible $d$ value.

The idea is to eliminate a constant fraction of elements of $M$ iteratively until only one element remains; the remaining candidate is the answer.
Initially, all elements in all columns are candidates.
Since the algorithm will remove elements gradually, for each column, we maintain a sub-column of remaining elements. 

In each iteration, first pick all median elements in all sub-columns. Then, find the median, $m$, among all medians. If $m$ leads to a feasible partition, then we know that the true answer is no greater than $m$; otherwise, the true answer is no more than $m$. We apply saddleback search to prune all candidates that cannot be the answer.

Collecting all median elements and find the median among all medians takes $O(n)$ time. Since saddleback search also takes $O(n)$ time, each iteration takes $O(n)$ time as well. Because we eliminate at least a quarter of candidates in each iteration, the time complexity is $O(n \lg n)$.
\begin{remark}
This problem can be solved in linear time~\cite{Frederickson1991}.
\end{remark}
%Let $S(i, j)$ be 
%Let $F(n, k)$ be the difference between the largest and the smallest sum over all regions for an optimal solution of partition $n$ books into $k$ parts.
%
%The recurrence relation is
%\[ F(i, j) = \begin{cases}
%                    S(1, i) & j = 1 \\
%                    \min_k \max(F(i-k, k-1), S(i-k+1, j))
%                \end{cases}\]
\end{Answer}

\section{String}
\begin{Exercise}[title={Longest common substring problem},origin={NTU CSIE 97},difficulty=1]
Given two length-$n$ binary strings $A$ and $B$, consider the problem of computing a longest string $C$ that is a substring of both $A$ and $B$. You are asked to prove or disprove that this so-called \emph{longest common substring problem} can be solved in $O(n \lg n)$ time.
\end{Exercise}
\begin{Answer}
This problem is called the \href{https://en.wikipedia.org/wiki/Longest_common_substring_problem}{longest common substring problem}. Build a generalized suffix tree from $A$ and $B$. Find the deepest internal node that has leaves from two strings. The string corresponding to the path from the root to the deepest internal node is the longest common substring. Since building a suffix tree takes linear time, the time complexity is linear.
\end{Answer}

\section{Others}
\begin{Exercise}[title={Cycle detection problem},origin={MCU CSIE 95}]
Design an algorithm which detects whether there exists a cycle within a singly linked list. (Suppose that each node in this list contains data and next fields for storing data and the pointer to the next node respectively.) Please analyze the time and space complexities of your algorithm.
\end{Exercise}
\begin{Answer}
This problem is identical to the \href{https://en.wikipedia.org/wiki/Cycle_detection}{cycle detection problem}. Maintain two pointers, fast and slow, and traverse the linked list from head in parallel. The fast pointer traverse the list two nodes per iteration, while the slow pointer traverses one node. If the list contains a cycle, then these two pointers will point to the same node in some iteration. Otherwise, the fast pointer will achieve the end of the list. The time complexity is linear and the space usage is constant.

\begin{remark}
More information can be found in~\cite{Nesterenko2012}.
\end{remark}
\end{Answer}

\begin{Exercise}[origin={NCTU CSIE 91}]
Given a finite set $A$ and a mapping function $f$ from $A$ to itself, describe an algorithm to find a subset $S$ of $A$ with maximum size such that $f$ is one-to-one when restricted to $S$.
\end{Exercise}
\begin{Answer}
The idea is as follows: we repeatedly remove one element $x \in S$ such that $f(y) \neq x$ for all $y \in S$ until no such an element exists.

In implementation, we maintain an hashtable $h$, where $h[x]$ stores how many elements $y$ satisfy $f(y) = x$. In each iteration, eliminate an element $x$ with $h[x] = 0$, and decrement $h[f(x)]$, until $h[x] \neq 0$ for all x. The time complexity is $O(n^2)$.
\end{Answer}

\subsection{Query support}

\begin{Exercise}[origin={NTHU CSIE 100}]
Suppose we have $n$ ranges $[a_1, b_1], [a_2, b_2], \dots, [a_n, b_n]$, where all $a_i$'s are negative and all $b_i$'s are positive. We are asked to preprocess these ranges so that for any input value $x$, we can efficiently count the number of the ranges containing $x$. Design an efficient representation of the ranges so that the desired counting can be done in $O(\lg n)$ time. Your representation must take $O(n)$ space. Describe you representation and how to answer a query in $O(\lg n)$ time in details.
\end{Exercise}
\begin{Answer}
Suppose that $x$ is a positive number. Since $a_i$ is negative and $b_i$ is positive, we only need to count the number of intervals whose $b_i$ is larger than $x$. If we preprocess the ranges in order by $b_i$, counting the can be done in $O(\lg n)$ time by using binary search. The case in which $x$ is a negative number is symmetric.
\end{Answer}

\begin{Exercise}[title={Range minimum query problem},origin={NCTU BIOINFO 100},difficulty=1]
Suppose that we are given a sequence of $n$ unsorted values, say $x_1, x_2, \dots, x_n$, and at the same time, we are asked to quickly answer repeated queries defined as follows: Given $i$ and $j$, where $1 \leq i \leq j \leq n$, find the smallest value in $x_i, x_{i+1}, \dots, x_j$. Please design a data structure that uses $O(n)$ space and answers the queries in $O(\lg n)$ time.
\end{Exercise}
\begin{Answer}
This problem is called the \href{https://en.wikipedia.org/wiki/Range_minimum_query}{range minimum query problem}. 
We first divide $n$ values into blocks of size $\lg n$.
For a given query $(i, j)$, since each block has $O(\lg n)$ elements, the minimum among all elements in $i$'s block that are after $i$ can be found in $O(\lg n)$ time.
Similarly, the minimum among all elements in $j$'s block that are before $j$ can be found in $O(\lg n)$ time as well.

The problem becomes how to find the minimum of all full blocks between $i$ and $j$ in $O(\lg n)$ time.
We can precompute a matrix $M$, such that $M[s][k]$ is the minimum in blocks $s, s + 1, \dots, s + 2^k$.
The minimum of all full blocks between $i$ and $j$ can be found in $O(\lg n)$ time by reading $M$.
Since the number of blocks is $O(\frac{n}{\lg n})$, the size of $M$ is $O(\frac{n}{\lg n} \lg \frac{n}{\lg n}) = O(n)$.
\end{Answer}

\printbibliography[heading=subbibliography]
